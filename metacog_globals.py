import numpy as np
import metacog_function_builder

INPUT_ONE_HOT_LIMIT = 100
INPUT_BINARY_LIMIT = 20
INPUT_NUMBER_PROBLEMS = 100
INPUT_SIZE = 1
OUTPUT_SIZE = 1
HIDDEN_SIZE = 37
DROPOUT_RATE = 0.5
MINIBATCH_SIZE = 32
#EPOCHS = 120
EPOCHS = 50
TRAINING_PERCENT = 0.8
WEIGHT_INIT = "glorot_normal"

PRETRAINING_EPOCHS = 0

# Dataset globals
NUMBER_RANDOM_FUNCTIONS = 10
# ELEMENTARY_FUNCTIONS = [np.log, np.sqrt, np.exp, np.sin, np.cos, np.tan, np.radians, np.floor, np.ceil]
ELEMENTARY_FUNCTIONS = metacog_function_builder.getPolynomialFunctions(NUMBER_RANDOM_FUNCTIONS)
FUNCTIONS_RANGE_START = 1
FUNCTIONS_RANGE_END = 10
FUNCTIONS_NUMBER_PROBLEMS = 100


# META_INPUT_SIZE = INPUT_ONE_HOT_LIMIT + HIDDEN_SIZE
META_NUMBER_FUNCTION_CLASSES = len(ELEMENTARY_FUNCTIONS)
META_HIDDEN_SIZE = 32
META_DROPOUT_RATE = 0.5
META_HIST_SIZE = 20
META_HIST_ZERO_PROB = 1e-5
META_NUMBER_MODELS = 3
META_EPOCHS = 100
META_LEARNING_RATE = 0.0001
META_INPUT_SIZE = INPUT_ONE_HOT_LIMIT + META_HIST_SIZE * HIDDEN_SIZE
META_BATCH_SIZE = 128

META_DATASET_FILENAME = "metacog_dataset.h5"
META_DATASET_VALIDATION_FILENAME = "metacog_dataset_validation.h5"


WEIGHT_HISTORY_FILENAME = "weights_history.npy"
WEIGHT_HISTORY_VALIDATION_FILENAME = "weights_validation_history.npy"
ACTIVATION_HISTORY_FILENAME = "activations_history.npy"


# Movie globals
MOVIE_SIZE = 800
MOVIE_FRAME_RATE = 10
MOVIE_QUALITY = 17  # comparable to lossless is 17/18 (higher value is lower quality 0-51)


